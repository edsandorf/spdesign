---
title: "Generating a design"
output: 
  rmarkdown::html_vignette:
    toc: true
bibliography: references.bib
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Generating a design}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Generating a design

There are two key steps in generating a design. 

# The list of design options

The first step in generating a design is to specify the design options 

```{r, eval = FALSE}
design_opts <- list(
  optimization_algorithm = "random",
  efficiency_criteria = "d-error",
  model = "mnl",
  blocks = 1,
  tasks = 6,
  cores = 1
)
```

## Optimization algorithms
The choice of which algorithm to use depends on the design you are trying to find. 

### Modified Federov Algorithm 

The Modified Federov Algorithm is a row based algorithm [@hensher_applied_2005;@cook_comparison_1980]. This means that it samples rows (choice situations) from a candidate set. The candidate set can be the full factorial, indeed this is the default unless a candidate set is supplied or restrictions are specified through `opts$restrictions`, or a fractional factorial. Defining the allowed set of candidate choice tasks up front means that it is easy to remove bad alternatives and choice tasks prior to searching for design candidates and it is easy to implement constraints, for example that certain attribute levels cannot occur simultaneously within an alternative or choice task. However, it is very difficult to satisfy attribute level balance since it is necessary to check for balance each time a design candidate is selected from the candidate set. It is also important to note that using the MFA with large designs may be impossible due to memory constraints. Since it is necessary to specify the full factorial over all alternatives, the initial candidate set may become very large. So if the design is very large, it may be necessary to use the RSC algorithm to find a design (see below).





Steps involved in the algorithm

1. Determine the candidate set. In this package, the default is the full factorial and we remove all candidates implied by the restrictions passed through `opts$restrictions`. 
2. Select alternatives from the candidate set, combine into choice tasks and design candidate. Checks for attribute level balance if necessary. The default is to sample alternatives without replacement, which ensures that no choice task will contain identical alternatives nor will any given alternative be repeated across the design. The latter effect may lead to a less efficient design. Setting `opts$sample_with_replacement = TRUE` will sample with replacement from the candidate set. 
3. Calculate the specified error measures (see below).
4. Check if the current design is better than a previous design. 

Steps 2-4 are repeated until a specified efficiency threshold is met, the maximum number of iterations is reached or the user stops the search manually. 

### Relabeling, Swapping and Cycling (RSC)

The RSC algorithm is a column based algorithm [@hensher_applied_2005;@huber_importance_1996;@sandor_profile_2002].

1. Better for very large designs
2. Easy to satisfy attribute level balance
3. Harder to implement constraints, e.g. attribute levels cannot co-occur, because the constraints have to be checked after each relabeling, swapping and cycling iteration. 

## Efficiency criteria
When creating an efficient design, it is important to select the criteria used to measure efficiency. In `spdesign` you can specify one of the following:

### A-efficiency

The A-efficiency criteria, or A-error, seeks to minimize the trace of the variance covariance matrix. Effectively minimizing the sum of variances. This measure is not commonly used, likely because it tends to ignore covariances and is heavily influenced by the variance of one or a few parameters. 


$$
\mathrm{A} = \frac{\mathrm{tr}(\Omega)}{K}
$$
To use A-efficiency as the criteria to optimize the design simply specify: `efficiency_criteria = "a-error"`.

### C-efficiency

The C-efficiency criteria, or C-error, seeks to minimize the variance of the ratio of two parameters, e.g. willingness-to-pay, which is the ratio of the non-cost to the negative of the cost (or price) parameter when the utility function is separable, additive and linear in the parameters [@scarpa_design_2008]. Optimizing a design for the outcome of interest may in some cases be more useful than optimizing for smaller standard errors of the estimates themselves (which is the case of the D-error discussed below). 

This is specified as: `efficiency_criteria = "c-error"`. 

$$
\mathrm{C} = \mathrm{Var}\left(\frac{\beta_k}{-\beta_j}\right)\approx\beta_j^{-2}\left[\mathrm{Var}(\beta_k)-2\beta_k\beta_j^{-1}\mathrm{Cov}(\beta_k,\beta_j)+(\beta_k/\beta_j)^2\mathrm{Var}(\beta_j)\right]
$$

Where $\beta_j$ is the "cost"-parameter and $\beta_k$ a vector of non-cost parameters. It is important to note that if the prior for either the numerator or denominator is zero, the ratio is either 0 or $+\infty$ and the standard errors cannot be calculated. To use C-efficiency as the criteria to optimize the design simply specify: `efficiency_criteria = "c-error"`.

### D-efficiency
The D-efficiency criteria, or D-error, seeks to minimize the determinant of the variance-covariance matrix, which all else equal, leads to smaller standard errors. The idea being that you can get significance with a samller sample size if your design contains more information, i.e. more informative trade-offs. Unlike the A-error, the D-error considers the covariances as well as the only the variances and is less affected by very large variances for single parameters. 

$$
\mathrm{D} = \det\left(\Omega\left(\beta, X\right)\right)^{1/K}
$$
To use D-efficiency as the criteria to optimize the design simply specify: `efficiency_criteria = "d-error"`.

### S-efficiency

The S-efficiency measure, or S-error, calculates the theoretical lower-bound sample size necessary to obtain significant estimates for each parameter under the assumption that the priors are correct. The minimum required sample size is equal to the smallest sample size required for all parameters to be theoretically significant. However, it is strongly advised not to rely on these measures as an absolute because sampling issues and measurement errors could mean that larger sample sizes are needed.

$$
\mathrm{N} \geq \left(\frac{\mathrm{s.e.}_{j,k}(\beta, X)t_\alpha}{\beta_k}\right)^2
$$
where $N$ is the theoretical minimum sample size and $t_\alpha$ is the t-value corresponding to significance level $\alpha$ and is set by the researcher. It is important to note that in the case of zero priors, the S-error cannot be calculated and will return $+\infty$. To use S-efficiency as the criteria to optimize the design simply specify: `efficiency_criteria = "s-error"`.

## Draws
When creating a design using Bayesian priors, with random parameters or both, it is necessary to specify the type of draws to use and how many. While researchers agree that scrambled low-discrepancy sequences, e.g. Halton, Sobol or MLHS, perform better than non-scrambled and pseudo-random sequences [@train_discrete_2009; @hess_use_2006; @bhat_simulation_2003], some simulation evidence suggest that scrambled Sobol sequences perform best in simulation, especially as the number of random parameters increase [@czajkowski_simulation_2019]. For this reason, we have set scrambled Sobol as the default choice. The complete list of options is: `pseudo-random`, `mlhs`, `standard-halton`, `scrambled-halton`, `standard-sobol` and `scrambled-sobol`. The option is passed the list of options using `draws_type`. Note that if you use Halton or scrambled Halton draws, the same draws will be used for both the priors and the parameters. This is not advised and if you are optimizing a random parameter logit model with Bayesian priors, use a different set of draws! This issue is noted and can be tracked through the package's [GitHub repository](https://github.com/edsandorf/spdesign/issues/16), but is low priority to be fixed.

The next step is to specify the the number of draws to use. While we are using the same type of draws for both priors and parameters, we do allow the user to specify different number of draws for each. This is to allow the user to tweak the design optimization process between assumptions about how good their priors are and how precicesly they want to approximate the integral of the random parameter logit model. The number of draws are specified through the options `draws_priors` and `draws_params`, for priors and parameters respectively. The default values of both are set to 100 draws. 

# The candidate set 
When we use the Modified Federov Algorithm to find design candidates, we begin by defining the candidate set. The candidate set can be the full factorial or a fractional factorial design. Often, we find that not all combinations of the full factorial makes sense. For example, it could be that if the level of an attribute occurs in alternative one, then it has to take a different level in alternative 2 or that attribute levels within an alternative cannot occur simultaneously. To avoid this, it is important to exclude these choice tasks. There are two ways we can do this:

1) We supply a restricted candidate set using the option `candidate_set` in `generate_design`. Supplying a candidate set is only possible if you are using a Modified Federov Algorithm.
2) We specify restrictions in the list of options through `opts$restrictions`. These are either applied to the candidate set before searching for design candidates (in the case of the MFA) or after each relabeling, swapping or cycling step (in the case of the RSC algorithm). 

To illustrate how restrictions are applied, we will use the case of the candidate set. Consider the following full factorial generated from two attributes taking on two levels in a design with two alternatives.

Restrictions are specified as a list of the form of a list. To make it clear, let us illustrate with a simple example. Consider the following full factorial generated from two attributes taking on two levels: 

```
   alt1_x1 alt1_x2 alt2_x1 alt2_x2
1        0       0       0       0
2        1       0       0       0
3        0       1       0       0
4        1       1       0       0
5        0       0       1       0
6        1       0       1       0
7        0       1       1       0
8        1       1       1       0
9        0       0       0       1
10       1       0       0       1
11       0       1       0       1
12       1       1       0       1
13       0       0       1       1
14       1       0       1       1
15       0       1       1       1
16       1       1       1       1
```

Notice that this candidate set is in the 'wide' format with a prefix corresponding to the alternative. The name of the prefix is determined based on the names of the alternatives in the list of utilities. Furthermore, let us assume that both attributes cannot simultaneously take on the value of 1. To implement this restriction, we would specify: 

```
opts <- list(
  restrictions = list(
    "alt1_x1 == 1 & alt1_x2 == 1",
    "alt2_x1 == 1 & alt2_x2 == 1"
  )
)
```

We specify a separate list element for each alternative. If we had specified all in a single character string, then we would only exclude alternatives where all attributes in all alternatives were equal to 1. In this case, we did not want that. It is similarly possible to specify restrictions that work across alternatives, for example that `alt1_x1` and `alt2_x2` cannot be 1 at the same time:

and if they both couldn't be 0 at the same time as well, we would specify: 
 
```
opts <- list(
  restrictions = list(
    "alt1_x1 == 1 & alt2_x2 == 1"
  )
)
```

The user familiar with R will notice that this is the exact same syntax we would use to subset a matrix. 

# The list of utility functions 

## A no choice or opt out alternative
The 'no choice' or 'opt out' alternative has to be explicitly included with a utility of zero. This is to ensure correct estimation of the variance-covariance matrix. 

## Selecting priors

In the case of of zero priors and attribute level balance, then the most efficient design will be an orthogonal design [@hensher_applied_2005, p. 268]. 

# Inspecting the design

## Dominant/dominated alternatives
Dominant or dominated alternatives should be avoided at all cost. The inclusion of such alternatives in the design and by extension the data will lead to bias in the estimated parameters [@hensher_applied_2005]. It is important to manually inspect all designs for potential dominating alternatives by considering the sign of the priors and the levels of the attributes in each alternative and choice task.

# References
